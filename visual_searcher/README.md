## Цель проекта
Построить мультимодальную модель, способную по текстовому описанию находить наиболее релевантные изображения из набора.  
Задача сводится к регрессии: модель предсказывает числовую степень соответствия "текст ↔ изображение".

## Описание данных
Имеются пары:
- `image` — путь к изображению
- `text` — текстовое описание (query)
- `score` — целевая переменная: оценка релевантности от 0 до 1

## Этапы проекта

1. **Векторизация изображений**:
   - Использована архитектура **ResNet18**
   - Удалены fully connected слои
   - Применён `AdaptiveAvgPool2d` для получения вектора признаков

2. **Векторизация текстов**:
   - Модель: `all-MiniLM-L6-v2` (SentenceTransformer)
   - Использован метод `.encode()` для получения эмбеддингов

3. **Объединение эмбеддингов**:
   - Текст + изображение → единый вектор
   - Матрица признаков: (4076, 2348)

4. **Разделение данных**:
   - Использован `GroupShuffleSplit`, чтобы исключить попадание одинакового изображения в train и test

5. **Обучение моделей**:
   - DummyRegressor (базовая)
   - Ridge-регрессия
   - **MLP (нейросеть)**: 5 скрытых слоёв, Dropout, BatchNorm, ReLU, Adam, EarlyStopping
   - Лучшая метрика: **RMSE ≈ 0.2646**

6. **Визуализация результатов**:
   - Для каждого запроса сформирован top-10 изображений
   - Визуальный анализ показывает разумную релевантность

## Результаты

- Лучшая модель: **MLP**
- RMSE: **0.2646**
- Модель успешно обучена находить совпадения между текстом и изображением
- Наилучшее качество достигнуто после масштабирования входных данных

## Выводы и рекомендации

Модель демонстрирует устойчивое соответствие простым запросам (человек, животное), но страдает от недостатка разнообразия в выдаче.

### Возможности улучшения:
- Расширение выборки
- Более глубокие модели (Transformer, SBERT + triplet loss)
- Более мощные эмбеддеры (CLIP, BLIP)
- Подбор другой функции потерь (например, contrastive loss)
